name: Update Magazine News

on:
  schedule:
    - cron: '0 * * * *'  # Suoritetaan kerran tunnissa
  workflow_dispatch:      # Mahdollistaa manuaalisen käynnistyksen GitHubin kautta
  push:
    branches:
      - main
    paths-ignore:
      - 'data.json'
      - 'stats.json'
      - 'sources/**'
      - 'failed_feeds.txt'

jobs:
  build:
    runs-on: ubuntu-latest
    
    # Tarvitaan oikeudet kirjoittaa tiedostoja takaisin arkistoon
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'

      - name: Install dependencies
        run: npm install axios rss-parser cheerio

      - name: Run Fetch Script
        env:
          SHEET_CSV_URL: ${{ secrets.SHEET_CSV_URL }}
        run: node fetch_news.js

      - name: Show failed feeds
        if: always()
        run: if [ -f failed_feeds.txt ]; then cat failed_feeds.txt; fi

      - name: Commit and push changes
        run: |
          git config --global user.name 'NewsRobot'
          git config --global user.email 'robot@openmag.fi'
          
          # 1. Haetaan GitHubin nykytilanne ja pakotetaan paikallinen tila vastaamaan sitä
          git fetch origin main
          git reset --mixed origin/main

          # 2. Lisätään robotin luoma uusi data
          git add -f data.json stats.json last_clean.txt
          
          # Lisätään sources ja poistetaan sieltä ne, jotka robotti deletoi (kuten se ongelmalähde)
          if [ -d "sources" ]; then
            git add -A sources/*.json || true
          fi
          
          git add failed_feeds.txt || true
          
          # 3. Tehdään commit ja pakotetaan push (force)
          if ! git diff --cached --quiet; then
            git commit -m "Automated news update [skip ci]"
            git push origin main --force
          else
            echo "Ei uutta tallennettavaa."
          fi
